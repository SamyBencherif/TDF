<!DOCTYPE html>
<html>
<body>
<h2> Object Model Standard 2019-08-24 </h2>

<h3>Agenda</h3>

<p>
    <ol type="I">
        <li> <a href="#Foreword"> Foreword </a> </li>
	<li> <a href="#Standard"> Current &amp; Past Standards </a> </li>
        <li> <a href="#Linearity"> Linearity  </a> </li>
	<li> <a href="#Challenges"> Challenges </a> </li>
	<li> <a href="#Closing"> Closing </a> </li>
	<li> <a href="#Footnotes"> Footnotes </a> </li>
    </ol>
</p>

<h3 id="Foreword"> Foreword </h3>

<p>
A TD source program exists in a simple format which aims to be easy
to understand and analyze. We have invented this language to allow us
to provide very special constructs to testbed programmers--such as the
<i>invariant</i>. There are various reasons why it is not a such a good
idea to simply pass a TD program to the testbed. One reason is
overhead; interpreted code tends to run slower than transpiled code.
A secondary reason organization, it is easier to separate
testbed code from language interpretation code if they are never run
on the same machine! To solve these problems we introduce an
intermediary format: The Object Model. The Object Model provides that
the semantics (the intention) of a program does not change once it is
transpiled--EXCEPT hardware specific details such as pin numbers. For
example, the implementation of the invariant structure will be codified
into the Object Model, such that an adjustment to the implementation,
say reducing variance in <i>wait</i> durations, does not effect prior
programs unless they are retranspiled. This contrasts something like
redefining the pin numbers of LED#1; that change immediately applies
to all TD programs, source or transpiled, because it exists within the
testbed codebase. This document contains explanations and specification
regarding the Object Model, as well as some information about the
translation of TD source programs into the Object Model format.
</p>

<h3 id="Standard"> Current and Past Standards </h3>

<p>
By definition, the Object Model is a C function. The Object Model is
designed to closely interact with the testbed codebase which, at the
time of writing, is understood to be compatible with C object files.
In fact, that is where the name of the model comes from. The intended
result is that a TD source program may be transpiled-compiled to a C
object file and header file which may be accessed directly from the
testbed codebase. You can imagine the programs will be linked
in a way that resembles:
<p>

<pre>
    cc -o test-bed-main.o td-prog-1.o td-prog-2.o ... hardware-config.o
</pre>

<p>
Previously, the object model consisted of a memory layout, that was
generated by a special function at runtime. This method was rejected
in favor of a more direct representation--albeit less amenable to
static analysis. As a resulted it is declared that validation must be
done strictly in advance of transpilation. And tentative plans
regarding an additional intermediary stage are in way. Either case, all
transpilation stages must be proven to be <i>semantically homomorphic
</i> (does not change the meaning of the program).
</p>

<h3 id="Linearity"> Linearity </h3>

<p>
For performance and simplification of implementation and implementation
changes, a recurring theme, we opt to keep the Object Model in a
'linear' form. To best demonstrate, consider the following NON-'linear'
program.
</p>

<pre>
    void eval_prog(prog* p)
    {
        while(p-&gt;current_instruction != NULL)
        {
            result* res = doStep(p-&gt;current_instruction);
            if (res == failed)
            {
                return failed;
            }
            if (res-&gt;is_invariant)
            {
                stoInvariants(res);
            }
            advanceProgInstruction(p);
        }
    }
</pre>

<p>
There is much looping and branching--while provable, it is
unnecessarily complex, especially considering the wide range of
programs that might be stored in 'p'. There is no reason to
generalize autogenerated programs. Generally imposes variability, risk.
Instead consider the following 'linearized' program.
</p>

<pre>
    void run_prog_td_led()
    {
        if (td_check_invariants() == failed)
        {
            td_simple_abort();
        }
        td_set_light(OFF);
        if (td_check_invariants() == failed)
        {
            td_simple_abort();
        }
        td_wait(1000);
        if (td_check_invariants() == failed)
        {
            td_simple_abort();
        }
        td_wait(1000);
        td_set_light(ON);
        if (td_check_invariants() == failed)
        {
            td_simple_abort();
        }
        td_wait(1000);
        if (td_check_invariants() == failed)
        {
            td_simple_abort();
        }
        td_set_light(OFF);
        if (td_check_invariants() == failed)
        {
            td_simple_abort();
        }
    }
</pre>

<p>
Perhaps not so fun to read. Repetitive as all get out, but this program
is not intended for the reader, it is simply a set of instructions for
the compiler (who produces the final .o file). The branching is simple.
If an invariant is broken, one can expect the line of execution to be
inside of an abort sequence.
</p>

<h3 id="Challenges"> Challenges </h3>

<p>
Conceptual challenges such as
<i>invariant testing latency<sup>1</sup></i>,
<i>adjusted time partitioning<sup>2</sup></i>, and
<i>invariant subcategories<sup>3</sup></i> are subject,
perhaps, to a need for tuning and would, under a generic model, induce
non-linear structures. Something along the lines of storage and referral
(in which case state-fullness would be the culprit) or inclusion of
separate cases for instructions and invariant testing within a loop
that traverses a linked list. Problems with the latter include a
resistance to time partitioning. As a result, the explicit model is
adopted, and the viability for object model validation is lost. To make
up for this: (1) an exceptionally rigorous transpilation step is needed
and (2) TD language validation shall be devised--whether or not with
the inclusion of a new linearized, pre-object model intermediary is
not decided at this time (see datestamp).
</p>

<p>
TD program validation is a critical step that, due to timing
constraints, is not planned to ship with the
initial release of the TD transpiler. It is not recommended to run
any testbed programs until a validation suite is also released.
Engineers are welcome to examine and verify the release
as well as implement hardware level configuration in the meantime.
</p>

<h3 id="Closing"> Closing </h3>

<p>
The Object Model specification can be stated simply. The Object Model
is a sub-set of C functions, and hardware configuration is a collection
of C functions. The meaningful outcomes of a program should be codified
in source TD program and its object model. Excluding hardware
configuration, it should not be possible to change the meaning of a
TD program by modifying the testbed codebase.
</p>

<h3 id="Footnotes"> Footnotes </h3>

<h4>1: Invariant Testing Latency</h4>

<p>
TD programs are extensively time sensitive. If we run (TD source,
pseudo):
</p>

<pre>
    set valve open
    wait 3000 ms
    set valve close
</pre>

<p>
We wish for the pause between those statements to be very close to
3000 ms. Compromise settles in, in service of invariant testing. Like
any computational effort, invariant testing takes some time. So
<i>adjusted time partitioning</i> may be desirable.
</p>

<h4>2: Adjusted Time Partitioning</h4>

<p>
First, to explain time partitioning in general, when we perform a 'wait'
of a specific duration, we might be interested in invariant test
results <i>during</i> that 'wait'. In fact, we are interested. We can
keep track of that information using time partitioning. Demonstrated
as so:
</p>

<pre>
     |___wait 1000 ms___| |___wait 1000 ms___| |___wait 1000 ms___|
                         ^                    ^
                         [check invariants]   [check invariants]
</pre>

<p>
Adjusted time partitioning is the practice of preforming the
first partition of, say a third the wait time, measuring the total
time of the first third plus the amount of time it takes to
preform the first invariant test, then taking the total desired
wait time minus this elapsed time, and now splitting it in half.
The process caries on in this manner. So, to wait 3000 ms:
</p>

<pre>
     |___wait 1000 ms___| &lt; [check elapsed] ...
    ^                    ^
    [start timer]        [check invariants]
</pre>

<p>
Say that took 1045 ms to complete. Now we have (3000-1045) = 1955 ms
left to wait. We then divide this job of waiting into two pieces.
Now (1955/2) = 977.5 ms of waiting remains. Here I show our timed
totals, starring the steps whose duration we do not control:
</p>

<pre>
    [wait: 1000 ms][*check: 45 ms][wait: 977.5 ms][*check: 16ms]
</pre>

<p>
And so the final wait time can be calculated to be (3000 - 2038.5) =
961.5 ms. As you can see, We can correct completely for <i>invariant
testing latency</i> as long as a final check at the end of the wait
can be forgone and the number of time partitions is not overly
ambitious. (Time Total / Partition Count should be &gt;&gt; max
invariant test latency.) Thanks to the inclusion of <i>Invariant
Subcategories</i> the TD programmer can have minimal influence of when
these tests are preformed.
</p>

<h4>3: Invariant Subcategories</h4>

<p>
This term refers to the inclusion of specific invariant types
such as 'before', 'during', and 'after', which specify invariant
test occurrence relative to an 'invariant' block in a TD program. For
example (TD pseudocode):
</p>

<pre>
    invariant
    before: during:
    moon_radius &gt; 500 m, earth_mass &lt; 1e9 kg,
    0 &lt; time, time &lt; 3000 ms;
    after:;
    {
        set valve open
        wait 3000 ms
    }
    invariant
    before: during:;
    after:
    time &lt; 3500 ms;
    {
        set valve closed;
    }

</pre>

<p>
This program makes use of invariant subcategory keywords to specify
that no invariant testing should occur between blocks 1 and 2. This
strategy is to be employed when precision in wait time is important
enough to forgo a system integrity check (invariant test). Try to use
this method sparingly.
</p>

</body>
</html>
